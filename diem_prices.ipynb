{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get price data from specific website\n",
    "Use requests, Beautiful Soup, and Pandas packages to retrieve html data from https://portland.hellodiem.com/, to locate product information, parse title and price into lists, remove superfluous pre-sale values, combine into a Pandas DataFrame, and save to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heading_list(url, page):\n",
    "    # Packages the request, send the request and catch the response: r\n",
    "    r = requests.get(url+'page/'+str(page)+'/')\n",
    "    html_text = r.text\n",
    "\n",
    "    #set soup list equal to html text from page\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    \n",
    "    headings = [[], []]\n",
    "    #get list of product title headings on page\n",
    "    headings[0] = soup.find_all('h2', class_='woocommerce-loop-product__title')\n",
    "    \n",
    "    #get list of product price headings on page\n",
    "    headings[1] = soup.find_all('span', class_='woocommerce-Price-amount amount')\n",
    "    pop_extra_price(headings[1])\n",
    "    return headings\n",
    "\n",
    "def pop_extra_price(headingss):\n",
    "    \"\"\"helper function to remove extra pre-sale prices from final list. Input list of \n",
    "    headers, get back list of headers less those that had a particular tag\"\"\"\n",
    "    for item in headingss:\n",
    "        if item.parent.name == 'del':\n",
    "            headingss.pop(headingss.index(item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_product(header_list):\n",
    "    \"\"\"input a list of tag-type values and return list of strings with surrounding html characters removed\"\"\"\n",
    "    string_list = ['' for item in range(len(header_list))]\n",
    "    for item in range(len(header_list)):\n",
    "        string_list[item] = str(header_list[item])[44:-5]\n",
    "    return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_price(header_list):\n",
    "    \"\"\"input a list of tag-type values and return list of strings with surrounding html characters removed\"\"\"\n",
    "    string_list = ['' for item in range(len(header_list))]\n",
    "    for item in range(len(header_list)):\n",
    "        string_list[item] = str(header_list[item])[101:-7]\n",
    "    return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "max_page = 12\n",
    "url = 'https://portland.hellodiem.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list to hold lists of headers, one for each page\n",
    "h_product = ['' for strng in range(max_page)]\n",
    "h_price = ['' for strng in range(max_page)]\n",
    "\n",
    "#iterate over each list of headers for a page, set each index of headers equal to list\n",
    "for page in range(0, max_page):\n",
    "    headers = get_heading_list(url, page+1)\n",
    "    h_product[page] = headers[0]\n",
    "    h_price[page] = headers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_products = []\n",
    "combined_prices = []\n",
    "\n",
    "for sublist in range(max_page):\n",
    "    combined_products.append(strip_product(h_product[sublist]))\n",
    "    \n",
    "for sublist in range(max_page):\n",
    "    combined_prices.append(strip_price(h_price[sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of all prices\n",
    "all_prices = []\n",
    "for by_page in combined_prices:\n",
    "    for li in by_page:\n",
    "        #print(li, '\\n')\n",
    "        all_prices.append(float(li))\n",
    "        \n",
    "#create a list of all products\n",
    "all_products = []\n",
    "for by_page in combined_products:\n",
    "    for li in by_page:\n",
    "        #print(li, '\\n')\n",
    "        all_products.append(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "product_ser = pd.Series(all_products)\n",
    "price_ser = pd.Series(all_prices)\n",
    "pot = pd.DataFrame([all_products, all_prices]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pot.to_csv('prices05082018.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.338862559241704"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pot[1].mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "page = 1\n",
    "r = requests.get(url+'page/'+str(page)+'/')\n",
    "html_text = r.text\n",
    "\n",
    "#set soup list equal to html text from page\n",
    "soup = BeautifulSoup(html_text, 'html.parser')\n",
    "\n",
    "#get list of product price headings on page\n",
    "headingss = soup.find_all('span', class_='woocommerce-Price-amount amount')\n",
    "\n",
    "#get list of product sale prices\n",
    "sale_price = soup.find_all('del')\n",
    "\n",
    "#print(soup.html.body.main.find('ul', class_='products columns-4').find('a'))\n",
    "#print(tag)\n",
    "#print(len(headingss))\n",
    "#print(headingss)\n",
    "#print(sale_price)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#print(h_product[0])\n",
    "print(strip_product(h_price[sublist]))\n",
    "print(strip_price(h_product[sublist]))\n",
    "#something is wrong wiht the helper fxn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
